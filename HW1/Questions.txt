Question 1:

Initial Probaility Vector  pi:

[P(c1) P(C2)] = [0.5 0.5]


Transisition Probability Matrix A:

[0.5 0.5]
[0.5 0.5]


Observation probability Matrix B:

[0.9 0.1]
[0.5 0.5]

Question 2:
Multiplying our A matrix with our PI vector gives us an estimate of our states in the next timestep.
The equations in 2.3-2.5 calculates the probability of seeing heads when flipping a coin. 

Question 3:
If we multiply our estimate of states with the observation matrix we get an estimate of what emissions we may see. 

Question 4:
Every state is only dependant of its previous state. Our state estimate is only dependant of our last observation. 

Question 5:
N = number of states
T = length of observation sequence
Size of delta:  N*T
Size of delta_index = N*(T-1)


Question 6:
It is a result of the product rule. 


Question 7:
Yes. 1000 samples takes 2040 iterations
	10000 takes 15114 iterations
Convergance is when the A and B matrices values converges to the goal matrices. This however differs from the algorithms convergance. 
The algorithms convergance is when the sum(alphas) stop increasing. 

Question 8:
Different values in the A-matrix leads to different results. If our initial values are too far away we suffer the risk of getting stuck in a local minimum that is not the correct answer. 

Question 9:
We get values which does not correspond to a value in the generation matrices. 

If we choose too large dimensions we will suffer from overfitting - the model will have a lot more local minimums to get stuck in. 

If we choose too few the algorithm may never converge. 

Balancing these two can give us a hint on the number of states. 

Question 10:

Uniform: 3 iterations. Bad result. More or less the same values as the initialization matrices

diagonal: Dividing by zero -> result NaN

Close to solution: 1948 iterations. Closer than init-matrices but not perfect. Not much better than the init-matrices from question 7.

